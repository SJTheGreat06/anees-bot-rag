{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJTheGreat06/anees-bot-rag/blob/main/anees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4i-JV9lJFxb"
      },
      "source": [
        "# Installing all the requirements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-community langchain-core langchain-groq pypdf gpt4all faiss-cpu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GAT4EkVTJ7YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing APIs and it's keys"
      ],
      "metadata": {
        "id": "PsB22QJb8I3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "api_key = os.environ.get(\"GROQ_API_KEY\")\n"
      ],
      "metadata": {
        "id": "dBzjMdIvTKC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading TXT"
      ],
      "metadata": {
        "id": "-Fr8n1R38OWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4IS8cHdbJFxd"
      },
      "outputs": [],
      "source": [
        "# Text based data Ingestion\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "loader = TextLoader(\"data/anees_dataset.txt\")\n",
        "text_docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klTXe5RVJFxe"
      },
      "source": [
        "# Scraping Anees School Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVG_kI6eJFxf"
      },
      "outputs": [],
      "source": [
        "# Web Based Data Ingestion\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Load, chunk, and Index the contents of a Webpage\n",
        "loader = WebBaseLoader(\n",
        "    [\"https://aneesschool.com/life-at-anees/\", \"https://aneesschool.com/aims-objectives/\", \"https://aneesschool.com/vision-mission/\", \"https://aneesschool.com/academic-building/\", \"https://aneesschool.com/anees-core-team/\", \"https://aneesschool.com/message-from-ceo-cum-chairman/\", \"https://aneesschool.com/the-formative-years/\", \"https://aneesschool.com/the-junior-school/\", \"https://aneesschool.com/the-middle-school/\", \"https://aneesschool.com/the-senior-school/\", \"https://aneesschool.com/personality-development/\", \"https://aneesschool.com/creative-skills/\", \"https://aneesschool.com/important-tips/\", \"https://aneesschool.com/student-participation/\", \"https://aneesschool.com/digital-campus/\", \"https://aneesschool.com/health-hygiene/\", \"https://aneesschool.com/transport-safety/\", \"https://aneesschool.com/auditorium/\", \"https://aneesschool.com/computer-lab/\", \"https://aneesschool.com/library/\", \"https://aneesschool.com/art-room/\", \"https://aneesschool.com/science-laboratories/\", \"https://aneesschool.com/sports/\", \"https://aneesschool.com/smart-spacious-classes/\"]\n",
        ")\n",
        "web_documents = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PmTLu0JFxf"
      },
      "source": [
        "# Loading PDF and its related data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zNcWD1hfJFxf"
      },
      "outputs": [],
      "source": [
        "# PDF Data Ingestion\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"data/Prospectus.pdf\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_5iRboHJFxg"
      },
      "source": [
        "# Chuncking all the data to meet the context length of the LLM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZkaX8VCeJFxg"
      },
      "outputs": [],
      "source": [
        "# Converting Text to chuncks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
        "text = text_splitter.split_documents(text_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_-KqiUQ3JFxh"
      },
      "outputs": [],
      "source": [
        "# Converting PDF text to chuncks\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
        "documents = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZoEwzyDqJFxh"
      },
      "outputs": [],
      "source": [
        "# Converting Web text to chuncks\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "web_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
        "web = web_splitter.split_documents(web_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "W-aeV-9bJFxh"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import GPT4AllEmbeddings\n",
        "dataBase1 = FAISS.from_documents(documents, GPT4AllEmbeddings())\n",
        "dataBase2 = FAISS.from_documents(web, GPT4AllEmbeddings())\n",
        "dataBase3 = FAISS.from_documents(text, GPT4AllEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhkRWkfrJFxh"
      },
      "outputs": [],
      "source": [
        "query = \"Fees\"\n",
        "result = dataBase3.similarity_search(query)\n",
        "result[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NiAiTSiNJFxh"
      },
      "outputs": [],
      "source": [
        "# Importing LLM and Implementing\n",
        "from langchain_groq import ChatGroq\n",
        "# Load Groq Gemma2\n",
        "llm = ChatGroq(model=\"gemma2-9b-it\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Master prompt"
      ],
      "metadata": {
        "id": "bZZyCkrK8WBB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GXQdlTpbJFxi"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Answer the question asked by the user only in the provided context.\n",
        "    Think step by step before answering questions and provide a detailed answer.\n",
        "    I will tip you $1000 if the user finds the answer helpful\n",
        "\n",
        "    Character: AneesBot, a formal and polite AI assistant employed by Anees School.\n",
        "\n",
        "    Task:\n",
        "    Respond to user inquiries about Anees School and its facilities in a professional, informative, and helpful manner.\n",
        "    Provide detailed and accurate information, adhering to the provided context.\n",
        "    Maintain a polite and courteous tone throughout the interaction, addressing all interactions with prospective parents beginning with \"Dear Parent,\" followed by the appropriate information.\n",
        "    Aim to keep responses within 500 characters. If necessary to provide a comprehensive and informative response, the character limit may be exceeded, but only when absolutely required and by a reasonable margin.\n",
        "\n",
        "    Guidelines:\n",
        "    Professionalism: Maintain a professional and courteous demeanor, avoiding slang or informal language.\n",
        "    Accuracy: Ensure the accuracy and relevance of all information provided.\n",
        "    Conciseness: Deliver information in a clear, concise, and easy-to-understand manner.\n",
        "    Context Awareness: If a user query falls outside the scope of school-related information, politely remind them of the context and request a rephrased question.\n",
        "    For example: \"Dear Parents, to best assist you, please limit your inquiries to questions about Anees School and its facilities. Could you please rephrase your question?\"\n",
        "\n",
        "    <context>\n",
        "    {context}\n",
        "    </context>\n",
        "    Question: {input}\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4wnIS-zpJFxi"
      },
      "outputs": [],
      "source": [
        "# Create stuff document chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "documentChain = create_stuff_documents_chain(llm, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ngqjsxqaJFxi"
      },
      "outputs": [],
      "source": [
        "retriever1 = dataBase1.as_retriever()\n",
        "retriever2 = dataBase2.as_retriever()\n",
        "retriever3 = dataBase3.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1Oc6X0eJFxi"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import MergerRetriever\n",
        "merger_retriever = MergerRetriever(retrievers=[retriever1, retriever2, retriever3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Y4N-esj-JFxi"
      },
      "outputs": [],
      "source": [
        "# Retriever Chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "retrievalChain = create_retrieval_chain(merger_retriever, documentChain)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output using LLM on RAG based context"
      ],
      "metadata": {
        "id": "zGz2vWft8fpQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0EPsXjjJFxi"
      },
      "outputs": [],
      "source": [
        "result = retrievalChain.invoke({\"input\":\"\"})\n",
        "print(result['answer'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}